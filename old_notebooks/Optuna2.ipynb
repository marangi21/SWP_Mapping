{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PqQ-NUZEugeu"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZf6es14BooK",
    "outputId": "bf6b933a-c096-4799-85f4-9b32cb22cbec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Note: using colab\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#usa una GPU se disponibile\n",
    "device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\") # 'cuda' if torch.cuda.is_available() else\n",
    "try:\n",
    "  import google.colab\n",
    "  COLAB = True\n",
    "  print(\"Note: using colab\")\n",
    "except:\n",
    "  print(\"Note: not using colab\")\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjBXaORnvrx2"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_count, out_count, hidden_layers, neurons_per_layer, dropout_rates):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.neurons_per_layer = neurons_per_layer\n",
    "\n",
    "        # Define input layer\n",
    "        self.input_layer = nn.Linear(in_count, neurons_per_layer[0])\n",
    "\n",
    "        # Define hidden layers\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for i in range(self.hidden_layers):\n",
    "            self.hidden.append(nn.Linear(neurons_per_layer[i], neurons_per_layer[i+1]))\n",
    "\n",
    "        # Define output layer\n",
    "        self.output_layer = nn.Linear(neurons_per_layer[-1], out_count)\n",
    "\n",
    "        # Define dropout layers with different dropout rates\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(p=dropout_rates[i]) for i in range(len(dropout_rates))])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for i in range(self.hidden_layers):\n",
    "            x = F.relu(self.hidden[i](x))\n",
    "            x = self.dropouts[i](x)  # Apply dropout with rate dropout_rates[i]\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHbul-pb5haZ"
   },
   "outputs": [],
   "source": [
    "def objective(trial, dataset, labels, device, batch_size, num_epochs):\n",
    "  dropout_rates = [trial.suggest_float(f'dropout_rate_{i}', 0.1, 0.5) for i in range(5)] #suggerisci dropout rates\n",
    "  hidden_layers = trial.suggest_int('hidden_layers', 1, 5) #suggerisci numero di hidden layers\n",
    "  neurons_per_layer = [trial.suggest_int(f'neurons_per_layer_{i}', 16, 1024) for i in range(hidden_layers+1)] #suggerisci il  numero di neuroni per layer\n",
    "  learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1) #suggerisci learning rate\n",
    "\n",
    "  #Inizializza il modello con gli iperparametri suggeriti\n",
    "  model = Net(in_count=dataset.shape[1], out_count=1, hidden_layers=hidden_layers, neurons_per_layer=neurons_per_layer, dropout_rates=dropout_rates)\n",
    "\n",
    "  #definizione datasets e dataloaders\n",
    "  X_train, X_val, y_train, y_val = train_test_split(dataset, labels, test_size = 0.2, random_state=42)\n",
    "  X_train = torch.Tensor(X_train.values).float()\n",
    "  y_train = torch.Tensor(y_train.values).float()\n",
    "  X_val = torch.Tensor(X_val.values).float().to(device)\n",
    "  y_val = torch.Tensor(y_val.values).float().to(device)\n",
    "  batch_size = batch_size\n",
    "  dataset_train = TensorDataset(X_train, y_train.unsqueeze(1))\n",
    "  dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "  dataset_val = TensorDataset(X_val, y_val.unsqueeze(1))\n",
    "  dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  #loss function ed ottimizzatore\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "  #addestramento del modello\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in dataloader_train:\n",
    "      #Forward pass\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      #Backward pass e ottimizzazione\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    #Validation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dataloader_val:\n",
    "        outputs = model(inputs)\n",
    "        val_loss = criterion(outputs, labels)\n",
    "\n",
    "  #Computa e ritorna loss sul validation set\n",
    "  return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iVXYd2nsAFiw",
    "outputId": "eb0838f2-49ae-433c-eab0-3dfa643a497f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 10:12:34,306] A new study created in memory with name: no-name-3bbf4439-a2e0-447c-bf16-132b5eaab2a8\n",
      "Optimizing:   0%|          | 0/50 [00:00<?, ?it/s][I 2024-03-13 10:14:01,116] Trial 0 finished with value: 40.091583251953125 and parameters: {'dropout_rate_0': 0.14848992562237195, 'dropout_rate_1': 0.14794615979913242, 'dropout_rate_2': 0.4857782584540963, 'dropout_rate_3': 0.18163165622899655, 'dropout_rate_4': 0.37586815284152997, 'hidden_layers': 1, 'neurons_per_layer_0': 180, 'neurons_per_layer_1': 248, 'learning_rate': 0.08255216559152308}. Best is trial 0 with value: 40.091583251953125.\n",
      "Optimizing:   2%|▏         | 1/50 [01:26<1:10:53, 86.80s/it][I 2024-03-13 10:22:55,617] Trial 1 finished with value: 9.49713134765625 and parameters: {'dropout_rate_0': 0.4753129394766763, 'dropout_rate_1': 0.4830921512616019, 'dropout_rate_2': 0.34879457663162744, 'dropout_rate_3': 0.48045822339584565, 'dropout_rate_4': 0.19476816032838695, 'hidden_layers': 4, 'neurons_per_layer_0': 229, 'neurons_per_layer_1': 756, 'neurons_per_layer_2': 867, 'neurons_per_layer_3': 424, 'neurons_per_layer_4': 215, 'learning_rate': 0.018372015123171263}. Best is trial 1 with value: 9.49713134765625.\n",
      "Optimizing:   4%|▍         | 2/50 [10:21<4:40:07, 350.15s/it][I 2024-03-13 10:26:39,643] Trial 2 finished with value: 30.995845794677734 and parameters: {'dropout_rate_0': 0.34727113806927656, 'dropout_rate_1': 0.3144842317661636, 'dropout_rate_2': 0.3991158754974873, 'dropout_rate_3': 0.13752490773383708, 'dropout_rate_4': 0.26322562233532054, 'hidden_layers': 1, 'neurons_per_layer_0': 614, 'neurons_per_layer_1': 662, 'learning_rate': 0.026496344021974972}. Best is trial 1 with value: 9.49713134765625.\n",
      "Optimizing:   6%|▌         | 3/50 [14:05<3:49:10, 292.56s/it][I 2024-03-13 10:30:33,155] Trial 3 finished with value: 26.810766220092773 and parameters: {'dropout_rate_0': 0.22962837899420543, 'dropout_rate_1': 0.4974623961415673, 'dropout_rate_2': 0.12811932834352358, 'dropout_rate_3': 0.2897236818433443, 'dropout_rate_4': 0.4492108322016932, 'hidden_layers': 1, 'neurons_per_layer_0': 1020, 'neurons_per_layer_1': 392, 'learning_rate': 0.04963854470584336}. Best is trial 1 with value: 9.49713134765625.\n",
      "Optimizing:   8%|▊         | 4/50 [17:58<3:26:25, 269.25s/it][I 2024-03-13 10:31:54,455] Trial 4 finished with value: 45.352603912353516 and parameters: {'dropout_rate_0': 0.22089506837227169, 'dropout_rate_1': 0.13315729138692314, 'dropout_rate_2': 0.16716737049017594, 'dropout_rate_3': 0.2984736974905302, 'dropout_rate_4': 0.3886969166846259, 'hidden_layers': 1, 'neurons_per_layer_0': 162, 'neurons_per_layer_1': 165, 'learning_rate': 0.03917534734959185}. Best is trial 1 with value: 9.49713134765625.\n",
      "Optimizing:  10%|█         | 5/50 [19:20<2:31:06, 201.47s/it][I 2024-03-13 10:38:46,400] Trial 5 finished with value: 77.36134338378906 and parameters: {'dropout_rate_0': 0.24353783393112471, 'dropout_rate_1': 0.40579761605521814, 'dropout_rate_2': 0.40886691689761967, 'dropout_rate_3': 0.15403956957601408, 'dropout_rate_4': 0.415347354217683, 'hidden_layers': 4, 'neurons_per_layer_0': 1020, 'neurons_per_layer_1': 582, 'neurons_per_layer_2': 28, 'neurons_per_layer_3': 668, 'neurons_per_layer_4': 305, 'learning_rate': 0.08503683119457471}. Best is trial 1 with value: 9.49713134765625.\n",
      "Optimizing:  12%|█▏        | 6/50 [26:12<3:20:13, 273.03s/it][I 2024-03-13 10:40:33,210] Trial 6 finished with value: 37.27327346801758 and parameters: {'dropout_rate_0': 0.4206084264420422, 'dropout_rate_1': 0.41955357315516517, 'dropout_rate_2': 0.4038658580064174, 'dropout_rate_3': 0.324318384485608, 'dropout_rate_4': 0.1271136219551409, 'hidden_layers': 1, 'neurons_per_layer_0': 849, 'neurons_per_layer_1': 49, 'learning_rate': 0.02823749841107562}. Best is trial 1 with value: 9.49713134765625.\n",
      "Optimizing:  14%|█▍        | 7/50 [27:58<2:36:43, 218.69s/it][I 2024-03-13 10:43:18,706] Trial 7 finished with value: 32.42140579223633 and parameters: {'dropout_rate_0': 0.2636532388933812, 'dropout_rate_1': 0.13148263722277553, 'dropout_rate_2': 0.300638586841355, 'dropout_rate_3': 0.22873865156535939, 'dropout_rate_4': 0.16745299239294265, 'hidden_layers': 1, 'neurons_per_layer_0': 660, 'neurons_per_layer_1': 343, 'learning_rate': 0.028124545934548172}. Best is trial 1 with value: 9.49713134765625.\n",
      "Optimizing:  16%|█▌        | 8/50 [30:44<2:21:13, 201.76s/it][I 2024-03-13 10:49:47,463] Trial 8 finished with value: 9.142688751220703 and parameters: {'dropout_rate_0': 0.26513807434114633, 'dropout_rate_1': 0.1435753163457274, 'dropout_rate_2': 0.18942242969835538, 'dropout_rate_3': 0.16852547300021237, 'dropout_rate_4': 0.3719132249326901, 'hidden_layers': 3, 'neurons_per_layer_0': 926, 'neurons_per_layer_1': 308, 'neurons_per_layer_2': 813, 'neurons_per_layer_3': 349, 'learning_rate': 0.08091919357614687}. Best is trial 8 with value: 9.142688751220703.\n",
      "Optimizing:  18%|█▊        | 9/50 [37:13<2:57:48, 260.22s/it][I 2024-03-13 10:53:19,017] Trial 9 finished with value: 18.311552047729492 and parameters: {'dropout_rate_0': 0.3746351965488538, 'dropout_rate_1': 0.4849750636078557, 'dropout_rate_2': 0.12590289071189256, 'dropout_rate_3': 0.14841298948446122, 'dropout_rate_4': 0.40294816718450766, 'hidden_layers': 2, 'neurons_per_layer_0': 239, 'neurons_per_layer_1': 854, 'neurons_per_layer_2': 150, 'learning_rate': 0.02395479579737751}. Best is trial 8 with value: 9.142688751220703.\n",
      "Optimizing:  20%|██        | 10/50 [40:44<2:43:27, 245.19s/it][I 2024-03-13 11:06:05,278] Trial 10 finished with value: 15.153420448303223 and parameters: {'dropout_rate_0': 0.10709712724591386, 'dropout_rate_1': 0.22423676605656084, 'dropout_rate_2': 0.22064280378337836, 'dropout_rate_3': 0.42281866052148565, 'dropout_rate_4': 0.30137023201181, 'hidden_layers': 5, 'neurons_per_layer_0': 459, 'neurons_per_layer_1': 960, 'neurons_per_layer_2': 968, 'neurons_per_layer_3': 115, 'neurons_per_layer_4': 943, 'neurons_per_layer_5': 409, 'learning_rate': 0.0986213746399113}. Best is trial 8 with value: 9.142688751220703.\n",
      "Optimizing:  22%|██▏       | 11/50 [53:30<4:23:01, 404.67s/it][I 2024-03-13 11:14:18,272] Trial 11 finished with value: 9.35429859161377 and parameters: {'dropout_rate_0': 0.4967864282325421, 'dropout_rate_1': 0.2723751813668517, 'dropout_rate_2': 0.27079260490971263, 'dropout_rate_3': 0.496253176286651, 'dropout_rate_4': 0.223655850386334, 'hidden_layers': 3, 'neurons_per_layer_0': 400, 'neurons_per_layer_1': 743, 'neurons_per_layer_2': 855, 'neurons_per_layer_3': 310, 'learning_rate': 0.0020522452636204808}. Best is trial 8 with value: 9.142688751220703.\n",
      "Optimizing:  24%|██▍       | 12/50 [1:01:43<4:33:18, 431.54s/it][I 2024-03-13 11:19:44,693] Trial 12 finished with value: 9.248966217041016 and parameters: {'dropout_rate_0': 0.496861093797566, 'dropout_rate_1': 0.24778247661350966, 'dropout_rate_2': 0.23249879200670862, 'dropout_rate_3': 0.3826664751101522, 'dropout_rate_4': 0.273935194774968, 'hidden_layers': 3, 'neurons_per_layer_0': 443, 'neurons_per_layer_1': 470, 'neurons_per_layer_2': 647, 'neurons_per_layer_3': 292, 'learning_rate': 0.002611373792501863}. Best is trial 8 with value: 9.142688751220703.\n",
      "Optimizing:  26%|██▌       | 13/50 [1:07:10<4:06:28, 399.69s/it][I 2024-03-13 11:25:20,425] Trial 13 finished with value: 9.998544692993164 and parameters: {'dropout_rate_0': 0.3164776500202849, 'dropout_rate_1': 0.20880394390031734, 'dropout_rate_2': 0.21389094572937953, 'dropout_rate_3': 0.38019844498489436, 'dropout_rate_4': 0.31544525478567753, 'hidden_layers': 3, 'neurons_per_layer_0': 762, 'neurons_per_layer_1': 435, 'neurons_per_layer_2': 576, 'neurons_per_layer_3': 259, 'learning_rate': 0.05431280520679686}. Best is trial 8 with value: 9.142688751220703.\n",
      "Optimizing:  28%|██▊       | 14/50 [1:12:46<3:48:13, 380.37s/it][I 2024-03-13 11:35:44,102] Trial 14 finished with value: 7.1876912117004395 and parameters: {'dropout_rate_0': 0.4140477574368812, 'dropout_rate_1': 0.20142862860391417, 'dropout_rate_2': 0.2070118152449848, 'dropout_rate_3': 0.22617679237756175, 'dropout_rate_4': 0.49170561051448725, 'hidden_layers': 4, 'neurons_per_layer_0': 36, 'neurons_per_layer_1': 518, 'neurons_per_layer_2': 608, 'neurons_per_layer_3': 901, 'neurons_per_layer_4': 820, 'learning_rate': 0.06574142813436815}. Best is trial 14 with value: 7.1876912117004395.\n",
      "Optimizing:  30%|███       | 15/50 [1:23:09<4:24:39, 453.71s/it][I 2024-03-13 11:43:46,921] Trial 15 finished with value: 9.138607025146484 and parameters: {'dropout_rate_0': 0.40097464154131923, 'dropout_rate_1': 0.18273367506981836, 'dropout_rate_2': 0.17700683847946744, 'dropout_rate_3': 0.22100909637564953, 'dropout_rate_4': 0.4831274983651415, 'hidden_layers': 4, 'neurons_per_layer_0': 61, 'neurons_per_layer_1': 280, 'neurons_per_layer_2': 304, 'neurons_per_layer_3': 966, 'neurons_per_layer_4': 797, 'learning_rate': 0.07117796615518772}. Best is trial 14 with value: 7.1876912117004395.\n",
      "Optimizing:  32%|███▏      | 16/50 [1:31:12<4:22:04, 462.47s/it][I 2024-03-13 11:57:28,401] Trial 16 finished with value: 6.359807014465332 and parameters: {'dropout_rate_0': 0.41591015022339967, 'dropout_rate_1': 0.18911979283989108, 'dropout_rate_2': 0.2820909341786777, 'dropout_rate_3': 0.23163306363346092, 'dropout_rate_4': 0.48293757697284967, 'hidden_layers': 5, 'neurons_per_layer_0': 102, 'neurons_per_layer_1': 572, 'neurons_per_layer_2': 325, 'neurons_per_layer_3': 968, 'neurons_per_layer_4': 829, 'neurons_per_layer_5': 943, 'learning_rate': 0.06526616931140546}. Best is trial 16 with value: 6.359807014465332.\n",
      "Optimizing:  34%|███▍      | 17/50 [1:44:54<5:13:44, 570.43s/it][I 2024-03-13 12:10:34,183] Trial 17 finished with value: 6.047084808349609 and parameters: {'dropout_rate_0': 0.4385765688655173, 'dropout_rate_1': 0.3174804132102478, 'dropout_rate_2': 0.30688902965587783, 'dropout_rate_3': 0.10376779971509717, 'dropout_rate_4': 0.4703187677862866, 'hidden_layers': 5, 'neurons_per_layer_0': 77, 'neurons_per_layer_1': 568, 'neurons_per_layer_2': 366, 'neurons_per_layer_3': 1017, 'neurons_per_layer_4': 665, 'neurons_per_layer_5': 1016, 'learning_rate': 0.058097357559192306}. Best is trial 17 with value: 6.047084808349609.\n",
      "Optimizing:  36%|███▌      | 18/50 [1:57:59<5:38:44, 635.14s/it][I 2024-03-13 12:22:00,288] Trial 18 finished with value: 4.438940525054932 and parameters: {'dropout_rate_0': 0.4517797526309439, 'dropout_rate_1': 0.3246838798027433, 'dropout_rate_2': 0.31642602556486654, 'dropout_rate_3': 0.11833624681638971, 'dropout_rate_4': 0.4453969292213948, 'hidden_layers': 5, 'neurons_per_layer_0': 321, 'neurons_per_layer_1': 614, 'neurons_per_layer_2': 346, 'neurons_per_layer_3': 729, 'neurons_per_layer_4': 581, 'neurons_per_layer_5': 990, 'learning_rate': 0.057167204323363745}. Best is trial 18 with value: 4.438940525054932.\n",
      "Optimizing:  38%|███▊      | 19/50 [2:09:25<5:36:03, 650.45s/it][I 2024-03-13 12:34:18,060] Trial 19 finished with value: 6.381731033325195 and parameters: {'dropout_rate_0': 0.44872636006172634, 'dropout_rate_1': 0.31879214028557523, 'dropout_rate_2': 0.34170486571833136, 'dropout_rate_3': 0.11435702993369057, 'dropout_rate_4': 0.337161801346785, 'hidden_layers': 5, 'neurons_per_layer_0': 326, 'neurons_per_layer_1': 1011, 'neurons_per_layer_2': 368, 'neurons_per_layer_3': 707, 'neurons_per_layer_4': 513, 'neurons_per_layer_5': 1009, 'learning_rate': 0.0477626673552931}. Best is trial 18 with value: 4.438940525054932.\n",
      "Optimizing:  40%|████      | 20/50 [2:21:43<5:38:19, 676.66s/it][I 2024-03-13 12:46:04,400] Trial 20 finished with value: 3.83974027633667 and parameters: {'dropout_rate_0': 0.33028819254508157, 'dropout_rate_1': 0.3677670371721876, 'dropout_rate_2': 0.33936844258479043, 'dropout_rate_3': 0.10003079964391409, 'dropout_rate_4': 0.44160065693384803, 'hidden_layers': 5, 'neurons_per_layer_0': 320, 'neurons_per_layer_1': 689, 'neurons_per_layer_2': 441, 'neurons_per_layer_3': 771, 'neurons_per_layer_4': 584, 'neurons_per_layer_5': 787, 'learning_rate': 0.05884773719618414}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  42%|████▏     | 21/50 [2:33:30<5:31:21, 685.57s/it][I 2024-03-13 12:57:48,000] Trial 21 finished with value: 5.589140892028809 and parameters: {'dropout_rate_0': 0.33462586921215143, 'dropout_rate_1': 0.354381166228823, 'dropout_rate_2': 0.3366694438378963, 'dropout_rate_3': 0.10529628812592096, 'dropout_rate_4': 0.4416227197443261, 'hidden_layers': 5, 'neurons_per_layer_0': 329, 'neurons_per_layer_1': 670, 'neurons_per_layer_2': 439, 'neurons_per_layer_3': 750, 'neurons_per_layer_4': 543, 'neurons_per_layer_5': 931, 'learning_rate': 0.057678314771938625}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  44%|████▍     | 22/50 [2:45:13<5:22:27, 690.98s/it][I 2024-03-13 13:08:39,718] Trial 22 finished with value: 6.105630874633789 and parameters: {'dropout_rate_0': 0.3123867855527344, 'dropout_rate_1': 0.37338326928072746, 'dropout_rate_2': 0.3500535412854904, 'dropout_rate_3': 0.1075790390496775, 'dropout_rate_4': 0.4362327697726045, 'hidden_layers': 5, 'neurons_per_layer_0': 334, 'neurons_per_layer_1': 686, 'neurons_per_layer_2': 463, 'neurons_per_layer_3': 742, 'neurons_per_layer_4': 485, 'neurons_per_layer_5': 725, 'learning_rate': 0.04075837731972385}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  46%|████▌     | 23/50 [2:56:05<5:05:38, 679.20s/it][I 2024-03-13 13:18:49,152] Trial 23 finished with value: 18.139842987060547 and parameters: {'dropout_rate_0': 0.3508376762827803, 'dropout_rate_1': 0.3629363620215587, 'dropout_rate_2': 0.4372791108534668, 'dropout_rate_3': 0.20103534400047857, 'dropout_rate_4': 0.3445689098557513, 'hidden_layers': 5, 'neurons_per_layer_0': 548, 'neurons_per_layer_1': 850, 'neurons_per_layer_2': 178, 'neurons_per_layer_3': 572, 'neurons_per_layer_4': 597, 'neurons_per_layer_5': 719, 'learning_rate': 0.07313112880495083}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  48%|████▊     | 24/50 [3:06:14<4:45:14, 658.27s/it][I 2024-03-13 13:27:09,702] Trial 24 finished with value: 5.349178314208984 and parameters: {'dropout_rate_0': 0.1909278234095271, 'dropout_rate_1': 0.36033428328726735, 'dropout_rate_2': 0.3214354169336186, 'dropout_rate_3': 0.13126412509142943, 'dropout_rate_4': 0.43638145543715995, 'hidden_layers': 4, 'neurons_per_layer_0': 338, 'neurons_per_layer_1': 658, 'neurons_per_layer_2': 472, 'neurons_per_layer_3': 808, 'neurons_per_layer_4': 390, 'learning_rate': 0.05974938438972972}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  50%|█████     | 25/50 [3:14:35<4:14:33, 610.94s/it][I 2024-03-13 13:38:11,809] Trial 25 finished with value: 5.120798110961914 and parameters: {'dropout_rate_0': 0.19029739261675194, 'dropout_rate_1': 0.4190345143171374, 'dropout_rate_2': 0.25338870086337617, 'dropout_rate_3': 0.2696243264961879, 'dropout_rate_4': 0.422184667684765, 'hidden_layers': 4, 'neurons_per_layer_0': 306, 'neurons_per_layer_1': 835, 'neurons_per_layer_2': 728, 'neurons_per_layer_3': 836, 'neurons_per_layer_4': 368, 'learning_rate': 0.03834511435658311}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  52%|█████▏    | 26/50 [3:25:37<4:10:31, 626.29s/it][I 2024-03-13 13:48:03,452] Trial 26 finished with value: 10.089137077331543 and parameters: {'dropout_rate_0': 0.1672877052886002, 'dropout_rate_1': 0.44107414621144253, 'dropout_rate_2': 0.24907128180915558, 'dropout_rate_3': 0.26148799603961376, 'dropout_rate_4': 0.3524033557278953, 'hidden_layers': 4, 'neurons_per_layer_0': 549, 'neurons_per_layer_1': 823, 'neurons_per_layer_2': 726, 'neurons_per_layer_3': 579, 'neurons_per_layer_4': 75, 'learning_rate': 0.04533654179971405}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  54%|█████▍    | 27/50 [3:35:29<3:56:05, 615.90s/it][I 2024-03-13 14:00:22,119] Trial 27 finished with value: 5.448329925537109 and parameters: {'dropout_rate_0': 0.37501687443885323, 'dropout_rate_1': 0.4490235407623714, 'dropout_rate_2': 0.36663795375515607, 'dropout_rate_3': 0.3514979197528218, 'dropout_rate_4': 0.4164889470806667, 'hidden_layers': 4, 'neurons_per_layer_0': 258, 'neurons_per_layer_1': 782, 'neurons_per_layer_2': 697, 'neurons_per_layer_3': 849, 'neurons_per_layer_4': 679, 'learning_rate': 0.0330213630008336}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  56%|█████▌    | 28/50 [3:47:47<3:59:20, 652.73s/it][I 2024-03-13 14:08:18,024] Trial 28 finished with value: 15.9710693359375 and parameters: {'dropout_rate_0': 0.2904228541615811, 'dropout_rate_1': 0.28422812087526017, 'dropout_rate_2': 0.25476543371757665, 'dropout_rate_3': 0.25866688995683895, 'dropout_rate_4': 0.45712308876977165, 'hidden_layers': 5, 'neurons_per_layer_0': 427, 'neurons_per_layer_1': 914, 'neurons_per_layer_2': 226, 'neurons_per_layer_3': 652, 'neurons_per_layer_4': 423, 'neurons_per_layer_5': 126, 'learning_rate': 0.011945318829701526}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  58%|█████▊    | 29/50 [3:55:43<3:29:53, 599.68s/it][I 2024-03-13 14:17:26,910] Trial 29 finished with value: 5.816974639892578 and parameters: {'dropout_rate_0': 0.13713797440416256, 'dropout_rate_1': 0.40420864774265103, 'dropout_rate_2': 0.44191998450176406, 'dropout_rate_3': 0.18239125076625545, 'dropout_rate_4': 0.3835603206830221, 'hidden_layers': 4, 'neurons_per_layer_0': 193, 'neurons_per_layer_1': 901, 'neurons_per_layer_2': 570, 'neurons_per_layer_3': 843, 'neurons_per_layer_4': 183, 'learning_rate': 0.03936247976628325}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  60%|██████    | 30/50 [4:04:52<3:14:48, 584.44s/it][I 2024-03-13 14:26:15,533] Trial 30 finished with value: 6.678337574005127 and parameters: {'dropout_rate_0': 0.18768734824894445, 'dropout_rate_1': 0.38225976868194483, 'dropout_rate_2': 0.49481962752318676, 'dropout_rate_3': 0.19146123569347046, 'dropout_rate_4': 0.4148747459102787, 'hidden_layers': 5, 'neurons_per_layer_0': 290, 'neurons_per_layer_1': 725, 'neurons_per_layer_2': 516, 'neurons_per_layer_3': 527, 'neurons_per_layer_4': 309, 'neurons_per_layer_5': 592, 'learning_rate': 0.07795741750179605}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  62%|██████▏   | 31/50 [4:13:41<2:59:46, 567.70s/it][I 2024-03-13 14:34:41,835] Trial 31 finished with value: 6.675875186920166 and parameters: {'dropout_rate_0': 0.20540341315505609, 'dropout_rate_1': 0.3287810226424949, 'dropout_rate_2': 0.31386013974248034, 'dropout_rate_3': 0.14286786179028882, 'dropout_rate_4': 0.44348960356837996, 'hidden_layers': 4, 'neurons_per_layer_0': 376, 'neurons_per_layer_1': 625, 'neurons_per_layer_2': 455, 'neurons_per_layer_3': 811, 'neurons_per_layer_4': 368, 'learning_rate': 0.06180177719917798}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  64%|██████▍   | 32/50 [4:22:07<2:44:46, 549.28s/it][I 2024-03-13 14:43:22,015] Trial 32 finished with value: 8.617541313171387 and parameters: {'dropout_rate_0': 0.14228260407298976, 'dropout_rate_1': 0.34807299205476133, 'dropout_rate_2': 0.3757867525977386, 'dropout_rate_3': 0.1271098147411948, 'dropout_rate_4': 0.4993721122442012, 'hidden_layers': 4, 'neurons_per_layer_0': 147, 'neurons_per_layer_1': 780, 'neurons_per_layer_2': 508, 'neurons_per_layer_3': 777, 'neurons_per_layer_4': 409, 'learning_rate': 0.053021524106651084}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  66%|██████▌   | 33/50 [4:30:47<2:33:09, 540.55s/it][I 2024-03-13 14:49:10,277] Trial 33 finished with value: 12.613914489746094 and parameters: {'dropout_rate_0': 0.18264100420510973, 'dropout_rate_1': 0.4459540472003544, 'dropout_rate_2': 0.3246724327599425, 'dropout_rate_3': 0.16600039156269106, 'dropout_rate_4': 0.36843143788398136, 'hidden_layers': 3, 'neurons_per_layer_0': 499, 'neurons_per_layer_1': 630, 'neurons_per_layer_2': 269, 'neurons_per_layer_3': 888, 'learning_rate': 0.06853099624164063}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  68%|██████▊   | 34/50 [4:36:35<2:08:45, 482.86s/it][I 2024-03-13 14:53:02,357] Trial 34 finished with value: 13.786584854125977 and parameters: {'dropout_rate_0': 0.11160054641781042, 'dropout_rate_1': 0.3912964796033136, 'dropout_rate_2': 0.2771543241509067, 'dropout_rate_3': 0.45668548655814867, 'dropout_rate_4': 0.43224522261605786, 'hidden_layers': 2, 'neurons_per_layer_0': 215, 'neurons_per_layer_1': 700, 'neurons_per_layer_2': 395, 'learning_rate': 0.08987205366611359}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  70%|███████   | 35/50 [4:40:28<1:41:54, 407.63s/it][I 2024-03-13 15:02:34,658] Trial 35 finished with value: 7.93528938293457 and parameters: {'dropout_rate_0': 0.2778578063085476, 'dropout_rate_1': 0.2952120368536909, 'dropout_rate_2': 0.2976116275337588, 'dropout_rate_3': 0.12850950632386224, 'dropout_rate_4': 0.3908416354643948, 'hidden_layers': 4, 'neurons_per_layer_0': 291, 'neurons_per_layer_1': 509, 'neurons_per_layer_2': 737, 'neurons_per_layer_3': 632, 'neurons_per_layer_4': 625, 'learning_rate': 0.04336608065177129}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  72%|███████▏  | 36/50 [4:50:00<1:46:38, 457.03s/it][I 2024-03-13 15:18:12,387] Trial 36 finished with value: 5.2428412437438965 and parameters: {'dropout_rate_0': 0.23128505595917517, 'dropout_rate_1': 0.34130645752277095, 'dropout_rate_2': 0.37370218696943913, 'dropout_rate_3': 0.20319617615461288, 'dropout_rate_4': 0.473265214047729, 'hidden_layers': 5, 'neurons_per_layer_0': 374, 'neurons_per_layer_1': 632, 'neurons_per_layer_2': 971, 'neurons_per_layer_3': 916, 'neurons_per_layer_4': 458, 'neurons_per_layer_5': 762, 'learning_rate': 0.033351185332448574}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  74%|███████▍  | 37/50 [5:05:38<2:10:16, 601.24s/it][I 2024-03-13 15:36:50,647] Trial 37 finished with value: 4.495728015899658 and parameters: {'dropout_rate_0': 0.235361769281193, 'dropout_rate_1': 0.341926524663649, 'dropout_rate_2': 0.37548684981119523, 'dropout_rate_3': 0.2728031343096739, 'dropout_rate_4': 0.46389507992329665, 'hidden_layers': 5, 'neurons_per_layer_0': 611, 'neurons_per_layer_1': 587, 'neurons_per_layer_2': 1020, 'neurons_per_layer_3': 898, 'neurons_per_layer_4': 706, 'neurons_per_layer_5': 772, 'learning_rate': 0.034244383398177446}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  76%|███████▌  | 38/50 [5:24:16<2:31:16, 756.35s/it][I 2024-03-13 15:49:15,376] Trial 38 finished with value: 5.654016971588135 and parameters: {'dropout_rate_0': 0.2509592083837802, 'dropout_rate_1': 0.25609228302005405, 'dropout_rate_2': 0.4278951496203497, 'dropout_rate_3': 0.27853688715201985, 'dropout_rate_4': 0.4548949265908023, 'hidden_layers': 5, 'neurons_per_layer_0': 577, 'neurons_per_layer_1': 412, 'neurons_per_layer_2': 893, 'neurons_per_layer_3': 444, 'neurons_per_layer_4': 721, 'neurons_per_layer_5': 796, 'learning_rate': 0.019381098657605244}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  78%|███████▊  | 39/50 [5:36:41<2:18:01, 752.86s/it][I 2024-03-13 15:58:38,662] Trial 39 finished with value: 78.45816802978516 and parameters: {'dropout_rate_0': 0.21514918424834606, 'dropout_rate_1': 0.4303083960182579, 'dropout_rate_2': 0.3955100132458593, 'dropout_rate_3': 0.3183016308867424, 'dropout_rate_4': 0.10018793872730819, 'hidden_layers': 5, 'neurons_per_layer_0': 706, 'neurons_per_layer_1': 792, 'neurons_per_layer_2': 61, 'neurons_per_layer_3': 709, 'neurons_per_layer_4': 576, 'neurons_per_layer_5': 527, 'learning_rate': 0.03450121543077129}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  80%|████████  | 40/50 [5:46:04<1:55:59, 695.99s/it][I 2024-03-13 16:18:52,787] Trial 40 finished with value: 13.194563865661621 and parameters: {'dropout_rate_0': 0.4722517467800132, 'dropout_rate_1': 0.40722490857119553, 'dropout_rate_2': 0.4731757716617397, 'dropout_rate_3': 0.3169428210514858, 'dropout_rate_4': 0.4029250969463026, 'hidden_layers': 5, 'neurons_per_layer_0': 627, 'neurons_per_layer_1': 593, 'neurons_per_layer_2': 1003, 'neurons_per_layer_3': 1012, 'neurons_per_layer_4': 729, 'neurons_per_layer_5': 866, 'learning_rate': 0.05037067167012972}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  82%|████████▏ | 41/50 [6:06:18<2:07:42, 851.43s/it][I 2024-03-13 16:33:49,333] Trial 41 finished with value: 6.063700199127197 and parameters: {'dropout_rate_0': 0.24516154979545673, 'dropout_rate_1': 0.34098156760241355, 'dropout_rate_2': 0.3788493060611607, 'dropout_rate_3': 0.2561525916830515, 'dropout_rate_4': 0.4649511119257746, 'hidden_layers': 5, 'neurons_per_layer_0': 481, 'neurons_per_layer_1': 538, 'neurons_per_layer_2': 951, 'neurons_per_layer_3': 918, 'neurons_per_layer_4': 470, 'neurons_per_layer_5': 671, 'learning_rate': 0.03504958042656996}. Best is trial 20 with value: 3.83974027633667.\n",
      "Optimizing:  84%|████████▍ | 42/50 [6:21:15<1:55:19, 864.96s/it][W 2024-03-13 16:34:43,703] Trial 42 failed with parameters: {'dropout_rate_0': 0.23005897449045326, 'dropout_rate_1': 0.33370670375205885, 'dropout_rate_2': 0.3609546147597148, 'dropout_rate_3': 0.28895180925358355, 'dropout_rate_4': 0.4769393097312337, 'hidden_layers': 5, 'neurons_per_layer_0': 147, 'neurons_per_layer_1': 732, 'neurons_per_layer_2': 808, 'neurons_per_layer_3': 926, 'neurons_per_layer_4': 568, 'neurons_per_layer_5': 827, 'learning_rate': 0.022683527460287095} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-27-6584d0964489>\", line 22, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, X_df_std, y_df, device, batch_size, num_epochs),\n",
      "  File \"<ipython-input-25-5c2d6144fc5e>\", line 31, in objective\n",
      "    outputs = model(inputs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"<ipython-input-22-31594f007a88>\", line 24, in forward\n",
      "    x = F.relu(self.hidden[i](x))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n",
      "[W 2024-03-13 16:34:43,705] Trial 42 failed with value None.\n",
      "Optimizing:  84%|████████▍ | 42/50 [6:22:09<1:12:47, 545.94s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6584d0964489>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   study.optimize(lambda trial: objective(trial, X_df_std, y_df, device, batch_size, num_epochs), \n\u001b[0m\u001b[1;32m     23\u001b[0m                  \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                  callbacks=[callback])\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-6584d0964489>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   study.optimize(lambda trial: objective(trial, X_df_std, y_df, device, batch_size, num_epochs), \n\u001b[0m\u001b[1;32m     23\u001b[0m                  \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                  callbacks=[callback])\n",
      "\u001b[0;32m<ipython-input-25-5c2d6144fc5e>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, dataset, labels, device, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;31m#Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-31594f007a88>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply dropout with rate dropout_rates[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dataset e parametri\n",
    "batch_size = 5094\n",
    "num_epochs = 20\n",
    "n_trials = 50\n",
    "\n",
    "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/training_set.csv\")\n",
    "X_df = df.drop(columns=['SWP'], axis=1)\n",
    "y_df = df['SWP']\n",
    "scaler = StandardScaler()\n",
    "features = df.drop(['Unnamed: 0', 'ID', 'ID_Pixel', 'ID_Albero', 'UTM_lon', 'UTM_lat','NDVI', 'SWP'], axis=1).columns.to_list()\n",
    "df2 = df[features]\n",
    "X_df_std = pd.DataFrame(scaler.fit_transform(df2[features]),\n",
    "                                  columns=features,\n",
    "                                  index=df2.index)\n",
    "joblib.dump(scaler, '/content/drive/My Drive/Colab Notebooks/scaler.pkl')\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "with tqdm(total=n_trials, desc=\"Optimizing\") as pbar:\n",
    "  def callback(study, trial):\n",
    "    pbar.update(1)\n",
    "  study.optimize(lambda trial: objective(trial, X_df_std, y_df, device, batch_size, num_epochs),\n",
    "                 n_trials=n_trials,\n",
    "                 callbacks=[callback])\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJz77maZTJ_F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
