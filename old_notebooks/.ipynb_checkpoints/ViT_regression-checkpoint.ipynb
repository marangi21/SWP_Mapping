{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a2f8c9-c5ef-440d-9925-e5ba8430f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c440cf4d-56ef-4905-8eb2-e92466e29bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import ViTModel\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce5164b-8da2-48de-8d58-46c2f7e34678",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (3071709677.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    class ViTFOrImageRegression(nn.Module):\u001b[0m\n\u001b[1;37m                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class ViTForImageRegression(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        num_channels = params['num_channels'] \n",
    "        num_hidden_layers = params['num_hidden_layers']\n",
    "        size_hidden_layers = params['size_hidden_layers']\n",
    "        dropout_rates = params['dropout_rates']\n",
    "        super(ViTModel, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79df06a4-dc28-4103-a7ee-cfd3f8a4568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTimgRegression(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(ViTimgRegression, self).__init__()\n",
    "\n",
    "        num_channels = params['num_channels'] \n",
    "        num_hidden_layers = params['num_hidden_layers']\n",
    "        size_hidden_layers = params['size_hidden_layers']\n",
    "        dropout_rates = params['dropout_rates']\n",
    "\n",
    "        self.feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(768, size_hidden_layers[0])\n",
    "\n",
    "        # Hidden layers\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for i in range(num_hidden_layers - 1):  # Loop until num_hidden_layers - 1\n",
    "            self.hidden.append(nn.Linear(size_hidden_layers[i], size_hidden_layers[i+1]))\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(size_hidden_layers[-1], 1)\n",
    "\n",
    "        # Dropout layers\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(p=dropout_rates[i]) for i in range(len(dropout_rates))])\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.feature_extractor(x)\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for i in range(num_hidden_layers - 1):  # Loop until num_hidden_layers - 1\n",
    "            x = F.relu(self.hidden[i](x))\n",
    "            x = self.dropouts[i](x)  # Apply dropout with rate dropout_rates[i]\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece9e57-767c-4d1c-bd90-3564a09c587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    num_channels = 11\n",
    "    num_hidden_layers = 3\n",
    "    size_hidden_layers = [512, 256, 128]\n",
    "    dropout_rates = [0.5, 0.5, 0.5]\n",
    "}\n",
    "epochs = 10\n",
    "batch_size = 1024\n",
    "learning_rate = 1e-4\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "model = ViTForImageRegression(params)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
